{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "DxkcnmfHw3xu"
      },
      "id": "DxkcnmfHw3xu"
    },
    {
      "cell_type": "markdown",
      "id": "4e2489cc",
      "metadata": {
        "id": "4e2489cc"
      },
      "source": [
        "### General data preparation\n",
        "The following splits the raw data set into training and testing data sets.\n",
        "\n",
        "After loading *carabids.csv* as `carabid`, we must do some data cleaning and initialize some objects.\n",
        "\n",
        "The function `%!in%` is effectively the opposite of `%in%` (i.e. it finds instances in x that are not in y).\n",
        "\n",
        "`sptable` allows species with few specimens (<30) to be easily identified (as `spname`). The \"correct\" cutoff value may change depending on your data's composition and objective of the model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "carabid = read.csv(file.choose())\n",
        "\n",
        "'%!in%' = function(x,y)!('%in%'(x,y))\n",
        "\n",
        "sptable = table(carabid$SpeciesName)\n",
        "spname = names(which(sptable < 30))\n",
        "\n",
        "#Train:Test ratio is 8:2, so I am initializing those values here\n",
        "fractionTraining = 0.8\n",
        "fractionvalid = 0.2\n",
        "\n",
        "seed = 123"
      ],
      "metadata": {
        "id": "KHS1Nv3ABWcP"
      },
      "id": "KHS1Nv3ABWcP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fc02e4bc",
      "metadata": {
        "id": "fc02e4bc"
      },
      "source": [
        "Next, we remove the species in `spname` and set the seed. Setting the seed will allow us to run this same code again and get the exact same split.\n",
        "\n",
        "When computing the sample size of the training dataset, we use `floor()` to round down to the nearest integer. You could also use `ceiling()` to round up, what matters is that we get a whole integer value.\n",
        "\n",
        "We then take a random sample from our dataset and turn that into our training dataset, with the remaining data being our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ee8e9e3",
      "metadata": {
        "id": "1ee8e9e3"
      },
      "outputs": [],
      "source": [
        "carabid_keep = subset(carabid, SpeciesName %!in% c('Carabidae sp.',spname))\n",
        "\n",
        "set.seed(seed)\n",
        "\n",
        "# Compute sample sizes.\n",
        "sampleSizeTraining = floor(fractionTraining * nrow(carabid_keep))\n",
        "\n",
        "# Create the randomly-sampled indices for the dataframe. Use setdiff() to\n",
        "# avoid overlapping subsets of indices.\n",
        "indicesTraining = sort(sample(seq_len(nrow(carabid_keep)), size=sampleSizeTraining))\n",
        "indicestest = setdiff(seq_len(nrow(carabid_keep)), indicesTraining)\n",
        "\n",
        "dfTraining = carabid_keep[indicesTraining, ]\n",
        "dfTest = carabid_keep[indicestest, ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0b6b696",
      "metadata": {
        "id": "b0b6b696"
      },
      "source": [
        "### Traditional machine learning preparation\n",
        "Now that we've split our data, we need to do some additional cleaning. First, we will remove unnecessary columns, confirm our predictor variables are numeric, and remove specimens with missing data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dd32453",
      "metadata": {
        "id": "6dd32453"
      },
      "outputs": [],
      "source": [
        "#Remove unnecessary columns\n",
        "remove = c(1:17,25,29:32,43,47:50,55:57,65,73,81,89,97,105)\n",
        "dfTraining = dfTraining[,-remove]\n",
        "dfTest = dfTest[,-remove]\n",
        "\n",
        "#Make predictor variables numeric\n",
        "numcols = ncol(dfTraining)\n",
        "dfTraining[,2:numcols] = as.data.frame(lapply(dfTraining[,2:numcols], as.numeric))\n",
        "dfTest[,2:numcols] = as.data.frame(lapply(dfTest[,2:numcols], as.numeric))\n",
        "\n",
        "#Find variables with missing values\n",
        "sapply(dfTraining, function(x) sum(is.na(x)))\n",
        "sapply(dfTest, function(x) sum(is.na(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a3539d6",
      "metadata": {
        "id": "7a3539d6"
      },
      "source": [
        "As we can see, some of the columns containing colour data have missing values. We can remove the rows with missing data and re-check our datasets to make sure there is no remaining missing data.\n",
        "\n",
        "These steps can also be completed before splitting the data, and you may want to ensure that removing specimens did not lower any species abundance below your cutoff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30084aa8",
      "metadata": {
        "id": "30084aa8"
      },
      "outputs": [],
      "source": [
        "#Find the name of the first column with missing values\n",
        "nacol = names(which(sapply(dfTraining, function(x) sum(is.na(x))) > 0))[1]\n",
        "                   \n",
        "dfTraining = dfTraining[-which(is.na(dfTraining[,nacol])),]\n",
        "dfTest = dfTest[-which(is.na(dfTest[,nacol])),]\n",
        "                           \n",
        "sapply(dfTraining, function(x) sum(is.na(x)))\n",
        "sapply(dfTest, function(x) sum(is.na(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a27f7fdc",
      "metadata": {
        "id": "a27f7fdc"
      },
      "source": [
        "Finally, we will standardize our data using the `preProcess` function from the `caret` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427e60aa",
      "metadata": {
        "id": "427e60aa"
      },
      "outputs": [],
      "source": [
        "normParam = preProcess(dfTraining)\n",
        "norm.train = predict(normParam, dfTraining)\n",
        "norm.test = predict(normParam, dfTest)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "138bcbb7",
      "metadata": {
        "id": "138bcbb7"
      },
      "source": [
        "### Deep learning data preparation\n",
        "\n",
        "To prepare our data for deep learning, we must set up our image directories.\n",
        "\n",
        "First, we must read in the filenames from our unsorted image directory and compare them to our tabular specimen data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81836062",
      "metadata": {
        "id": "81836062"
      },
      "outputs": [],
      "source": [
        "#Set \"image_directory\" to the directory where you store your unsorted images\n",
        "#image_directory = your_image_direcory\n",
        "filenames = list.files(image_directory)\n",
        "\n",
        "#Create vector of image names based on tabular data\n",
        "ImageLabels = carabid_keep$ImageLabel\n",
        "rois = carabid_keep$ROINumber\n",
        "DorsalLabels = paste0(substr(ImageLabels, 1, 15), rois, \".jpg\")\n",
        "#We only have the dorsal image names so far, so we must add the ventral names\n",
        "VentralLabels = paste0(substr(ImageLabels,1,8), \"VENTRAL.\", rois, \".jpg\")\n",
        "\n",
        "#Check to see if all specimens have matching dorsal and ventral images\n",
        "#If this comes back FALSE, there might be something wrong with your images, image names, or tabular data\n",
        "all(ImageLabels %in% filenames)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8639c61",
      "metadata": {
        "id": "a8639c61"
      },
      "source": [
        "Next, we can initialize some functions and objects that will help with our image sorting. `my.file.rename` will copy our files from the unsorted image directory to the sorted image directory. We use `file.copy` so that the original unsorted directory is left intact, but you can use `file.rename` if you don't want duplicate copies of your images. Leaving the original directory intact can be useful if you want to make changes to your training/testing datasets later on, but will take up more memory on your hard drive.\n",
        "\n",
        "`split` is a vector that will inform our code to put the images into either the training or testing directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fe8522",
      "metadata": {
        "id": "16fe8522"
      },
      "outputs": [],
      "source": [
        "my.file.rename <- function(from, to) {\n",
        "  todir <- dirname(to)\n",
        "  if (!isTRUE(file.info(todir)$isdir)) dir.create(todir, recursive=TRUE)\n",
        "  file.copy(from = from,  to = to)\n",
        "}\n",
        "\n",
        "split = vector(mode = 'character', length = ImageLabels)\n",
        "split[indicesTraining] = \"training\"\n",
        "split[indicesTest] = \"testing\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35344854",
      "metadata": {
        "id": "35344854"
      },
      "source": [
        "This loop will copy your unsorted images into a sorted directory with the structure \"/dataset/SpeciesName/filename\" (e.g. \"/training/Cyclotrachelus furtivus/BLAN_01_DORSAL.1.jpg\").\n",
        "\n",
        "`sites` and `sitedex` serve no purpose in the loop other than keeping track of progress, as this process can take some time if you have many images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b1e977",
      "metadata": {
        "id": "e7b1e977"
      },
      "outputs": [],
      "source": [
        "#Set \"sorted_directory\" to the directory where you will store your sorted images\n",
        "#sorted_directory = your_sorted_image_direcory\n",
        "\n",
        "sites = c()\n",
        "sitedex = 1\n",
        "for(filename in filenames){\n",
        "  if(filename %in% DorsalLabels){\n",
        "    taxadex = which(DorsalLabels == filename) %% length(DorsalLabels)\n",
        "    taxa = carabid_keep$SpeciesName[taxadex]\n",
        "    dataset = split[taxadex]\n",
        "    my.file.rename(from = paste(image_directory,filename, sep = \"/\"),\n",
        "                   to = paste(sorted_directory, dataset, taxa, filename, sep = \"/\"))\n",
        "  }\n",
        "  if(filename %in% VentralLabels){\n",
        "    taxadex = which(VentralLabels == filename) %% length(DorsalLabels)\n",
        "    taxa = carabid_keep$SpeciesName[taxadex]\n",
        "    dataset = split[taxadex]\n",
        "    my.file.rename(from = paste(image_directory,filename, sep = \"/\"),\n",
        "                   to = paste(sorted_directory, dataset, taxa, filename, sep = \"/\"))\n",
        "  }\n",
        "  if(substr(filename, 1, 4) %!in% sites){\n",
        "    sites[sitedex] = substr(filename, 1, 4)\n",
        "    sitedex = sitedex + 1\n",
        "    print(paste(\"Starting\", substr(filename, 1, 4), Sys.time()))\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traditional machine learning"
      ],
      "metadata": {
        "id": "3jmpRpwGwx26"
      },
      "id": "3jmpRpwGwx26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XGBoost\n",
        "The following code will train an eXtreme Gradient Boosting (XGBoost) model.\n",
        "\n",
        "Before we begin, we must load the `xgboost` R package."
      ],
      "metadata": {
        "id": "u1w9kmO8dFoh"
      },
      "id": "u1w9kmO8dFoh"
    },
    {
      "cell_type": "code",
      "source": [
        "library(xgboost)"
      ],
      "metadata": {
        "id": "DjmTDDaRdQpH"
      },
      "id": "DjmTDDaRdQpH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model requires labels to be numeric starting at 0. The training data must also be reformatted as an `xgb.DMatrix` object to be compatible with the model. You can also format the test data as an `xgb.DMatrix` and include it as part of the `watchlist` object. This will allow you to monitor the performance of the model on the test data while the model trains, which will allow you to determine if/when the model becomes overfit."
      ],
      "metadata": {
        "id": "O214OgIndU7R"
      },
      "id": "O214OgIndU7R"
    },
    {
      "cell_type": "code",
      "source": [
        "trainLabels = norm.train$SpeciesName\n",
        "testLabels = norm.test$SpeciesName\n",
        "\n",
        "trainlab = as.numeric(trainLabels) - 1\n",
        "testlab = as.numeric(testLabels) - 1\n",
        "\n",
        "dtrain <- xgb.DMatrix(label = trainlab, data = as.matrix(norm.train[,2:69]))\n",
        "dtest <- xgb.DMatrix(label = testlab, data = as.matrix(norm.test[,2:69]))\n",
        "watchlist = list(train = dtrain, test = dtest)"
      ],
      "metadata": {
        "id": "cRw8ibFidXlj"
      },
      "id": "cRw8ibFidXlj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally you can train your XGBoost model. A brief description of each of the model's parameters used here is as follows:\n",
        "\n",
        "`data`: Your `xgb.DMatrix` training data.\n",
        "\n",
        "`max.depth`: The maximum complexity of the model's trees. The higher this number is, the more variables each tree will consider.\n",
        "\n",
        "`eta`: The learning rate of the model (min approaches 0, max = 1).\n",
        "\n",
        "`nrounds`: The number of trees in the model. Increase this as you decrease `eta`.\n",
        "\n",
        "`watchlist`: Named datasets for model evaluation.\n",
        "\n",
        "`verbose`: The amount of information that will be printed as the model trains. 0 = no information, 1 = some evaluation metrics, 2 = more evaluation metrics.\n",
        "\n",
        "`num_class`: The number of 'classes' (i.e. species) in the model.\n",
        "\n",
        "`objective`: The objective function. Setting this as \"multi:softprob\" will give us a classification probability matrix when we classify new data with this model. Using \"multi:softmax\" would only give us the top-1 classifications without probabilities."
      ],
      "metadata": {
        "id": "I-MzebqQdbDo"
      },
      "id": "I-MzebqQdbDo"
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.train(data = dtrain, \n",
        "                max.depth = 9, \n",
        "                eta = 0.1, \n",
        "                nrounds = 400, \n",
        "                watchlist = watchlist,\n",
        "                eval.metric = \"merror\",\n",
        "                eval.metric = \"mlogloss\",\n",
        "                verbose = 1,\n",
        "                num_class = 25,\n",
        "                objective = \"multi:softprob\")"
      ],
      "metadata": {
        "id": "iq9N_8jfdgmz"
      },
      "id": "iq9N_8jfdgmz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can then make classifications using your model."
      ],
      "metadata": {
        "id": "yByZxiDSYnAR"
      },
      "id": "yByZxiDSYnAR"
    },
    {
      "cell_type": "code",
      "source": [
        "probs = predict(model, as.matrix(norm.test[,2:ncol(norm.test)]))"
      ],
      "metadata": {
        "id": "YfCgB95cYv5f"
      },
      "id": "YfCgB95cYv5f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data evaluation"
      ],
      "metadata": {
        "id": "wyIIL9fIfrxN"
      },
      "id": "wyIIL9fIfrxN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic metrics\n",
        "**(The following code also works with outputs from the deep learning tutorial)**\n",
        "\n",
        "Most basic performance metrics for your model can be easily measured using the `confusionMatrix` function from the `caret` package.\n",
        "\n",
        "To make our data compatible with the `confusionMatrix` function, we will need to convert our probability matrix to a vector of predicted classes."
      ],
      "metadata": {
        "id": "OgoQfld4Y_fx"
      },
      "id": "OgoQfld4Y_fx"
    },
    {
      "cell_type": "code",
      "source": [
        "library(caret)\n",
        "colnames(probs) = levels(as.factor(trainLabels))\n",
        "preds = apply(probs, MARGIN = 1, FUN = function(x){names(which.max(x))})\n",
        "confmat = confusionMatrix(as.factor(preds), as.factor(testLabels))"
      ],
      "metadata": {
        "id": "2SzIgd2YZAB5"
      },
      "id": "2SzIgd2YZAB5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy and related metrics can be found in `confmat$overall`.\n",
        "\n",
        "Many useful metrics for comparing performance within classes can be found in `confmat$byclass`, such as precision, recall, and F1 score. You can also measure the macro average of these metrics by taking measuring the average across all classes."
      ],
      "metadata": {
        "id": "l7Bf7y_cv4dV"
      },
      "id": "l7Bf7y_cv4dV"
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = confmat$overall[1]\n",
        "#Simply using mean() to measure macro averages can work, but might\n",
        "#give an incorrect result if values are missing\n",
        "f1 = sum(confmat$byclass[,\"F1\"], na.rm = T)/nrow(confmat$byclass)"
      ],
      "metadata": {
        "id": "FwCRABAfv6E_"
      },
      "id": "FwCRABAfv6E_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a confusion matrix is a great way to visualize how your model is making classifications. Using a confusion matrix, you can easily see which classes are being misclassified and what they are erroneously being classified as. You can create a confusion matrix using `confmat$table` and the `dcast` function from `reshape2`."
      ],
      "metadata": {
        "id": "2e7dKmnSv8SG"
      },
      "id": "2e7dKmnSv8SG"
    },
    {
      "cell_type": "code",
      "source": [
        "library(reshape2)\n",
        "conftab = as.data.frame(confmat$table)\n",
        "conftab = dcast(conftab, formula = Prediction~Reference)"
      ],
      "metadata": {
        "id": "KfBl1gm7v-Ov"
      },
      "id": "KfBl1gm7v-Ov",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Top x accuracy\n",
        "\n",
        "If you want to measure your model's accuracy if it had several attempts to make a classification, you can use these custom functions. `topxacc` will return your models accuracy when given 'x' number of attempts, while `topxpreds` returns the top 'x' most likely classifications for your test specimens. (e.g. top 3 accuracy or top 3 predictions).\n",
        "\n",
        "These functions work by finding the top 'x' highest probability classes for any given classification in your classification probability matrix."
      ],
      "metadata": {
        "id": "7UDF3a8sv_7H"
      },
      "id": "7UDF3a8sv_7H"
    },
    {
      "cell_type": "code",
      "source": [
        "topxacc = function(x, testlab, prob, numclass){\n",
        "  #Creating a dataframe of top 'x' predictions\n",
        "  topxpreds = data.frame(matrix(NA, nrow = nrow(prob), ncol = x))\n",
        "  for(i in 1:nrow(prob)){\n",
        "    #Each row is reordered by descending probability. The name of the top 'x' columns\n",
        "    #from each row are recorded in topxpreds\n",
        "    topxpreds[i,] =  as.numeric(names(prob[i,order(as.numeric(prob[i,]), decreasing = T)])[1:x])\n",
        "  }\n",
        "  topxaccuracy = sum(testlab == topxpreds)/length(testlab)\n",
        "  \n",
        "  return(topxaccuracy)\n",
        "}\n",
        "\n",
        "topxpreds = function(x, testlab, prob, numclass){\n",
        "  #Creating a dataframe of top 'x' predictions\n",
        "  topxpreds = data.frame(matrix(NA, nrow = nrow(prob), ncol = x))\n",
        "  for(i in 1:nrow(prob)){\n",
        "    #Each row is reordered by descending probability. The name of the top 'x' columns\n",
        "    #from each row are recorded in topxpreds\n",
        "    topxpreds[i,] =  as.numeric(names(prob[i,order(as.numeric(prob[i,]), decreasing = T)])[1:x])\n",
        "  }\n",
        "  \n",
        "  return(topxpreds)\n",
        "}\n",
        "\n",
        "top3acc = topxacc(3, testLabels, probs, 25)\n",
        "top3preds = topxpreds(3, testLabels, probs, 25)"
      ],
      "metadata": {
        "id": "wNXeMAQ9wBwi"
      },
      "id": "wNXeMAQ9wBwi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hierarchical classification\n",
        "\n",
        "Hierarchical classifiers allow you to make classifications at multiple taxonomic levels simultaneously. To set up a hierarchical classifier, you will need to make a taxonomic hierarchy dataframe for your data. First, create a vector called `hierarchylevels` that contains the column names in your dataset of the taxonomic levels you want to include. Then, use this custom `hierarchy` function to create your taxonomic hierarchy dataframe."
      ],
      "metadata": {
        "id": "V84hHnxuwFO0"
      },
      "id": "V84hHnxuwFO0"
    },
    {
      "cell_type": "code",
      "source": [
        "hierarchylevels = c(\"SpeciesName\", \n",
        "                    \"Genus\", \n",
        "                    \"Subtribe\", \n",
        "                    \"Tribe\", \n",
        "                    \"Supertribe\", \n",
        "                    \"Subfamily\")\n",
        "\n",
        "hierarchy = function(data, ranks){\n",
        "\n",
        "  baselabels = data[,ranks[1]]\n",
        "    \n",
        "  #Get all unique base labels\n",
        "  uniquelabels = levels(as.factor(baselabels))\n",
        "  \n",
        "  #Create hierarchy DF\n",
        "  hierarchy = data.frame(matrix(NA, nrow = length(baselabels), ncol = length(ranks)))\n",
        "  colnames(hierarchy) = ranks\n",
        "  #Set first column of DF as the unique baselabels\n",
        "  hierarchy[,1] = uniquelabels\n",
        "  #For loop starting with second taxonomic level/column\n",
        "  for(i in 2:ncol(hierarchy)){\n",
        "    #Iterate through each unique LITL label\n",
        "    for(j in 1:length(uniquelabels)){\n",
        "      row = which(baselabels == uniquelabels[j])[1]\n",
        "      if(which(ranks == LITLs[row]) < i){\n",
        "        hierarchy[j,i] = as.character(data[row,ranks[i]])\n",
        "      }\n",
        "      else{\n",
        "        hierarchy[j,i] = hierarchyignore[j,1]\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  return(hierarchy)\n",
        "}\n",
        "\n",
        "myhierarchy = hierarchy(carabid, hierarchylevels)"
      ],
      "metadata": {
        "id": "fEkxB493wH1N"
      },
      "id": "fEkxB493wH1N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have your hierarchy dataframe, you can use it as a reference to convert your model's classifications into hierarchical classifications using this custom `hpredict` function. You can also use `hpredict` on your test labels for easier comparison with with your hierarchical classifications. You can then measure performance metrics at any taxonomic level using `confusionMatrix`."
      ],
      "metadata": {
        "id": "youfjvxTwL7o"
      },
      "id": "youfjvxTwL7o"
    },
    {
      "cell_type": "code",
      "source": [
        "hpredict = function(preds, hierarchy){\n",
        "  #Initializing prediction dataframe\n",
        "  preddf = data.frame(matrix(NA, nrow = length(preds), ncol = ncol(hierarchy)))\n",
        "  colnames(preddf) = colnames(hierarchy)\n",
        "  preddf[,1] = preds\n",
        "  \n",
        "  \n",
        "  for(i in 2:ncol(hierarchy)){\n",
        "    for(j in 1:nrow(preddf)){\n",
        "      #For the current pred (in this case preddf[j,i-1]), find the first match\n",
        "      #in the hierarchy dataframe and assign the label in the next column up\n",
        "      #as preddf[j,i].\n",
        "      preddf[j,i] = hierarchy[which(hierarchy[,i-1] == preddf[j,i-1])[1], i]\n",
        "    }\n",
        "  }  \n",
        "}\n",
        "\n",
        "hpreds = hpredict(preds, myhierarchy)\n",
        "htest = hpredict(testLabels, myhierarchy)\n",
        "\n",
        "genusconfmat = confusionMatrix(as.factor(hpreds$Genus), as.factor(htest$Genus))"
      ],
      "metadata": {
        "id": "v6xPAmEVwPHh"
      },
      "id": "v6xPAmEVwPHh",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}