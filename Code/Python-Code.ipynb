{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TGQXw0VQeK-9"
   },
   "source": [
    "# Deep learning\n",
    "In this tutorial we will train convolutional neural network (CNN) classification models in Python. The following code requires tensorflow, pandas, and numpy installations. If you do not yet have tensorflow installed, follow the instructions here: https://www.tensorflow.org/install/pip. \n",
    "\n",
    "If you do not yet have pandas installed, follow the instructions here:https://pandas.pydata.org/docs/getting_started/install.html. \n",
    "\n",
    "If you do not yet have numpy installed, follow the instructions here: https://numpy.org/install/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xq9VcA1ReK_G"
   },
   "source": [
    "## Directory Setup\n",
    "To load the training and testing images,  the image directory structure needs a specific format, where the root directory (i.e. training directory) should contain subdirectories, and each subdirectory represents a distinct class (i.e. species). Each subdirectory should then contain the corresponding images belonging to that class. See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Set/\n",
    "    ├── Species_1/\n",
    "    │   ├── Sp1_image1.jpg\n",
    "    │   ├── Sp1_image2.jpg\n",
    "    │   └── ...\n",
    "    ├── Species_2/\n",
    "    │   ├── Sp2_image1.jpg\n",
    "    │   ├── Sp2_image2.jpg\n",
    "    │   └── ...\n",
    "    └── ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training and testing image sets need to be stored in separate directories, but must have the same structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "### ResNet-50\n",
    "For our first model, we will use the ResNet-50 architecture as the base to train a transfer-learned classification model. First, we must import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CTD7moxEeK_C"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "igrj6I90eK_D"
   },
   "source": [
    "Here we are initializing our image sizes, batch sizes, and image directories. All images will be resized to the specified image size (224⨉224 in this case). Setting the image size smaller will decrease the amount of information given to the model, but will make the model train more quickly. The opposite is true for larger images.\n",
    "\n",
    "Batch size determines how many images will be propagated through the model at a time. Large batch sizes are more memory intensive, and can take longer to train. You might need to change the batch size based on your hardware specifications.\n",
    "\n",
    "Set `mytrainingdirectory` and `mytestingdirectory` to the path where your training and testing images are stored, respectively. Also set `os.chdir(savedirectory)` to the directory you'd like the model to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N6PzKgQkeK_E"
   },
   "outputs": [],
   "source": [
    "img_height, img_width = (224,224)\n",
    "batch_size = 128\n",
    "\n",
    "train_data_dir = mytrainingdirectory\n",
    "test_data_dir = mytestingdirectory\n",
    "\n",
    "os.chdir(savedirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_w47RxqeK_F"
   },
   "source": [
    "`ImageDataGenerator` will generate batches of images that are normalized using a preprocessing function and augmented to the user's specifications. Image augmentations can increase the effective size and diversity of the training set, which can lead to enhanced performance and a reduction in overfitting. To get the most benefit from image augmentation, the augmentation's should be carefully chosen to match changes that might be expected in real data. For example, adding a vertical flip augmentation might not make sense if your model is unlikely to encounter any images where the subject is upside down. Some common augmentations include: \n",
    "- Flipping\n",
    "- Rotation\n",
    "- Translation\n",
    "- Scaling\n",
    "- Shearing\n",
    "- Gaussian noise\n",
    "- Adjustments to brightness/contrast\n",
    "\n",
    "Because the test image set is meant to simulate a real-life images unseen by the model, augmentations are not usually applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OEQnybLceK_F"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within `ImageDataGenerator`, we will use `flow_from_directory`. This will read in batches directly from our image directory, opposed to `flow`, which would read images preloaded into the Python environment. This makes `flow_from_directory` more memory efficient.\n",
    "\n",
    "Setting the seed within `flow_from_directory` makes the batches reproduceable, and setting `shuffle = True` for the training data can prevent the model from overfitting to sequences within the data (e.g. species 1 images appear first, then species 2, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-NjY48kaeK_H"
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_6_DXzaeK_I"
   },
   "source": [
    "This code sets the seed and ensures reproduceability for our model training. The training will work without this code, but the final model will be slighlty different each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJSRonOjeK_J"
   },
   "outputs": [],
   "source": [
    "seed_value= 321\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mKbukPOceK_K"
   },
   "source": [
    "Here we are defining our model architecture. As a base, we are using the ImageNet ResNet50, making this a transfer learning CNN. After this we add a global average pooling layer, one dense layer with ReLu activation, dropout layers before and after the dense layer, and a softmax classification layer (see the \"**Custom CNN**\" section for more information on these layers). \n",
    "\n",
    "We must also set the base layers as non-trainable so their weights are not modified.\n",
    "\n",
    "`EarlyStopping` is used to automatically stop the training procedure when the model performance plateaus on the validation image set. This helps ensure the model is not trained for too short or too long. In this code, the model will stop training if the validation loss is not improved for 10 epochs. Early stopping can be set to monitor validation accuracy instead by setting `monitor='val_loss'` to `monitor='val_accuracy'`.\n",
    "`ModelCheckpoint` is used in tandem with `EarlyStopping` to save the model using the weights from the best epoch.\n",
    "\n",
    "The model is then compiled and ready to be fit to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vibtTl6peK_K"
   },
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top = False, weights = 'imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x) \n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x) \n",
    "predictions = Dense(train_generator.num_classes, activation = 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = ModelCheckpoint('best_weights_ResNet50.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chk5Jn3BeK_L"
   },
   "source": [
    "This code trains the model using data from `train_generator` over a maximum of 100 epochs. If the conditions for early stopping are met before 100 epochs, the model will halt training and revert back to the epoch at which early stopping metric reached its peak. It is also tested using the test data after every epoch, which allows you to monitor its progression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3lkwsUkeK_L"
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "          epochs = 100,\n",
    "          validation_data = test_generator,\n",
    "          callbacks = [early_stopping, checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the model is trained, we can access its training history to plot its accuracy and loss progression across epochs. However, this is only possible in the Python environment the model was trained in, as the training history is not preserved when the model is saved to your computer's memory.\n",
    "\n",
    "The following code requires matplotlib. If you do not yet have matplotlib installed, follow the instructions here: https://matplotlib.org/stable/users/installing/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('ResNet-50 Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('ResNet-50 Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WO2R6ItXeK_M"
   },
   "source": [
    "Finally, we can load the model saved by `ModelCheckpoint` to create a prediction probability matrix and export it as a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8Hk5yXOeK_M"
   },
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model('best_weights_ResNet50.h5')\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "preds = model.predict(test_generator)\n",
    "preddf = pd.DataFrame(preds)\n",
    "preddf.to_csv(\"ResNet-Predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG16\n",
    "For our second model, we will use the VGG16 architecture as our base instead of the ResNet-50 architecture. The training procedure is extremely similar, with only a few small changes. Because of this, we will highlight the changes to the ResNet-50 code first, then provide the entire script to run train the model.\n",
    "\n",
    "First, we must load in the VGG16 modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other change to the code is to the `base_model`, where we use `VGG16` instead of `ResNet50`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entire script for the VGG16 model is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input, VGG16\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#\n",
    "# Load in images\n",
    "#\n",
    "\n",
    "img_height, img_width = (224,224)\n",
    "batch_size = 128\n",
    "\n",
    "train_data_dir = mytrainingdirectory\n",
    "test_data_dir = mytestingdirectory\n",
    "\n",
    "os.chdir(savedirectory)\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
    "                                   shear_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "#\n",
    "# Set seeds\n",
    "#\n",
    "\n",
    "seed_value= 321\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "#\n",
    "# Define & fit model\n",
    "#\n",
    "\n",
    "base_model = VGG16(include_top = False, weights = 'imagenet')\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.2)(x) \n",
    "x = Dense(1024, activation = 'relu')(x)\n",
    "x = Dropout(0.2)(x) \n",
    "predictions = Dense(train_generator.num_classes, activation = 'softmax')(x)\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = ModelCheckpoint('best_weights_VGG16.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "          epochs = 100,\n",
    "          validation_data = test_generator,\n",
    "          callbacks = [early_stopping, checkpoint])\n",
    "\n",
    "#\n",
    "# Plot training progression\n",
    "#\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('VGG16 Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "# Plot loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('VGG16 Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Make and save predictions\n",
    "#\n",
    "\n",
    "best_model = tf.keras.models.load_model('best_weights_VGG16.h5')\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "preds = model.predict(test_generator)\n",
    "preddf = pd.DataFrame(preds)\n",
    "preddf.to_csv(\"VGG16-Predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom CNN\n",
    "For our final model, we build a CNN with a custom architecture. The code has several differences to the transfer learning models. At first, we will only highlight the code that differs from the previous two models, then provide the entire script to train the model.\n",
    "\n",
    "First, we must load in the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,  Dense, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous models, we used the preprocessing functions that come with `ResNet50` and `VGG16`. When creating a custom CNN, you have the freedom to use your own preprocessing function (a common one being `rescale=1./255`), or use premade functions like the ones we used with `ResNet50` and `VGG16`. For the example dataset, we found that the ResNet-50 preprocessing function worked the best, so it is what we used. We also found image transformations decreased the model's performance, so we did not apply them and used one data generator for both the training and validation image sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(preprocessing_function = preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest change to the code comes when we are defining the model architecture. Rather than loading pretrained convolutional layers as our base model, we must define these layers ourselves. A brief description of each layer we used is provided below:\n",
    "\n",
    "`Sequential` is a container class that allows you to build models by stacking multiple layers on top of each other in a sequential manner. It simplifies the process of creating and managing deep learning models.\n",
    "\n",
    "`Conv2D` is a convolutional layer for 2D image data. They are the first layers of a CNN, and perform the main operation of convolution: extracting features from the input data. These layers slide multiple filters (i.e. \"kernels\") over the input to capture spatial patterns. Convolutional layers are commonly used in image recognition tasks.\n",
    "\n",
    "`MaxPooling2D` is a downsampling operation that reduces the spatial dimensions (width and height) of the input tensor while preserving the most important features. It divides the input into non-overlapping rectangular regions and outputs the maximum value within each region.\n",
    "\n",
    "`GlobalAveragePooling` computes the average value for each channel across the entire spatial dimensions of the input feature maps. It reduces the spatial dimensions to a fixed-length vector, summarizing the spatial information and allowing for efficient global representation of the input. It is commonly used to transition from convolutional layers to fully connected layers.\n",
    "\n",
    "`Dense` is a fully connected layer in TensorFlow where each neuron is connected to every neuron in the previous layer. It performs a linear operation on the input data followed by an activation function. The number of neurons in the dense layer determines the dimensionality of the layer's output.\n",
    "\n",
    "We use the *Rectified Linear Unit (ReLU)* activation function in our convolutional and fully connected layers, as this introduces non-linearity into the model, allowing the model to learn and approximate complex relationships between input data and output predictions.\n",
    "\n",
    "The final dense layer uses *softmax activation*, which converts its input into a probability distribution for the learned classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some other common layers that were not included in this model include:\n",
    "\n",
    "`BatchNormalization` normalizes the inputs of a neural network layer by adjusting and scaling them to improve training stability and performance. It helps to address the internal covariate shift problem and accelerates the training process by reducing the dependence on initialization and learning rate tuning.\n",
    "\n",
    "`Dropout` layers are used for regularization and help prevent overfitting. They randomly drop a certain percentage of the neurons during training (i.e. set the neuron output values to 0), forcing the network to learn more robust features.\n",
    "\n",
    "`Flatten` transforms a multi-dimensional tensor into a one-dimensional tensor. It \"flattens\" the input by reshaping the tensor to have a shape of (batch_size, total_number_of_elements). It is an alternative to `GlobalAveragePooling` for transitioning from convolutional layers to fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can print a summary of the model's architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remaining code is the same as the previous models. The entire script for the custom CNN is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,  Dense, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "#\n",
    "# Load in images\n",
    "#\n",
    "\n",
    "img_height, img_width = (224,224)\n",
    "batch_size = 128\n",
    "\n",
    "train_data_dir = mytrainingdirectory\n",
    "test_data_dir = mytestingdirectory\n",
    "\n",
    "save_dir = mysavedirectory\n",
    "\n",
    "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = True,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "\n",
    "test_generator = train_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size = (img_height, img_width),\n",
    "    batch_size = batch_size,\n",
    "    seed = 123,\n",
    "    shuffle = False,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "os.chdir(savedir)\n",
    "\n",
    "#\n",
    "# Set seeds\n",
    "#\n",
    "\n",
    "seed_value= 321\n",
    "\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "random.seed(seed_value)\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "#\n",
    "# Define & fit model\n",
    "#\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(train_generator.num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "checkpoint = ModelCheckpoint('best_weights_CNN.h5', monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "          epochs = 100,\n",
    "          validation_data = test_generator,\n",
    "          callbacks = [early_stopping, checkpoint])\n",
    "\n",
    "#\n",
    "# Plot training progression\n",
    "#\n",
    "\n",
    "# Plot accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Custom CNN Accuracy', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Accuracy', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper left', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "#Plot loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Custom CNN Loss', fontsize=16)\n",
    "plt.xlabel('Epoch', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(['Train', 'Validation'], loc='upper right', fontsize=12)\n",
    "plt.tick_params(axis='both', labelsize=12)\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "# Make and save predictions\n",
    "#\n",
    "\n",
    "best_model = tf.keras.models.load_model('best_weights_CNN.h5')\n",
    "\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "preds = model.predict(test_generator)\n",
    "preddf = pd.DataFrame(preds)\n",
    "preddf.to_csv(\"CNN-Predictions.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "After your model(s) has been trained and predictions have been made on a testing image set, we can measure the model's performance. The following code requires scikit-learn. If you do not yet have scikit-learn installed, follow the instructions here: https://scikit-learn.org/stable/install.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_curve, precision_recall_curve, auc, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will simply measure the accuracy and loss of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "valid_loss, valid_acc = best_model.evaluate(test_generator, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will measure F1 score, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have not run created the `preds` object, do so using:\n",
    "# np.random.seed(seed_value)\n",
    "# tf.random.set_seed(seed_value)\n",
    "# preds = best_model.predict(test_generator, verbose = 1)\n",
    "\n",
    "predicted_classes = tf.argmax(preds, axis=1)\n",
    "\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "report = classification_report(true_classes, \n",
    "                               predicted_classes, \n",
    "                               target_names=test_generator.class_indices,\n",
    "                               output_dict=True)\n",
    "\n",
    "macro_precision = report['macro avg']['precision']\n",
    "macro_recall = report['macro avg']['recall']\n",
    "macro_f1_score = report['macro avg']['f1-score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can measure top x accuracy (x = 3 in this example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_x = 3\n",
    "\n",
    "predicted_indices = tf.argsort(preds, axis=1)[:, -top_x:]\n",
    "\n",
    "top3_accuracy = np.mean(np.any(np.equal(predicted_indices, true_classes[:, np.newaxis]), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can generate a confusion matrix to visualize the distribution of classifications among out taxa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional metrics\n",
    "We can also make one-vs-rest ROC curves for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_index = test_generator.class_indices[class_name]\n",
    "    class_predictions = predictions[:, class_index]\n",
    "    class_true_labels = (true_classes == class_index).astype(int)\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(class_true_labels, class_predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve - Class {}'.format(class_name))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the same for PR curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "for class_name in class_names:\n",
    "    class_index = test_generator.class_indices[class_name]\n",
    "    class_predictions = predictions[:, class_index]\n",
    "    class_true_labels = (true_classes == class_index).astype(int)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(class_true_labels, class_predictions)\n",
    "    pr_auc = auc(recall, precision)\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(recall, precision, label='PR Curve (AUC = {:.2f})'.format(pr_auc))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Precision-Recall Curve - Class {}'.format(class_name))\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
