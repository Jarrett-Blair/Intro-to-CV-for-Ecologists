{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGQXw0VQeK-9"
      },
      "source": [
        "# Deep learning\n",
        "We must first import the modules required to train our model. If you do not yet have tensorflow installed, follow the instructions here: https://www.tensorflow.org/install/pip. If you do not yet have pandas installed, follow the instructions here:https://pandas.pydata.org/docs/getting_started/install.html. If you do not yet have numpy installed, follow the instructions here: https://numpy.org/install/."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTD7moxEeK_C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, ResNet50\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igrj6I90eK_D"
      },
      "source": [
        "Here we are initializing our image sizes, batch sizes, and image directories. All images will be resized to the specified image size (224â¨‰224 in this case). Setting the image size smaller will decrease the amount of information given to the model, but will make the model train more quickly. The opposite is true for larger images.\n",
        "\n",
        "Batch size determines how many images will be propagated through the model at a time. Large batch sizes are more memory intensive, and can take longer to train. You might need to change the batch size based on your hardware specifications.\n",
        "\n",
        "Set `mytrainingdirectory` and `mytestingdirectory` to the path where your training and testing images are stored, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6PzKgQkeK_E"
      },
      "outputs": [],
      "source": [
        "img_height, img_width = (224,224)\n",
        "batch_size = 128\n",
        "\n",
        "train_data_dir = mytrainingdirectory\n",
        "test_data_dir = mytestingdirectory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_w47RxqeK_F"
      },
      "source": [
        "`ImageDataGenerator` will generate our batches of images with several augmentation methods. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEQnybLceK_F"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function = preprocess_input,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True,\n",
        "                                   vertical_flip = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq9VcA1ReK_G"
      },
      "source": [
        "Within `ImageDataGenerator`, we will use `flow_from_directory`. This will read in batches directly from our image directory, opposed to `flow`, which would read images preloaded into the Python environment. This makes `flow_from_directory` less memory intensive.\n",
        "\n",
        "We create `train_generator` and `test_generator` with the same parameters, and the only differences being the image directory and that the `test_generator` is not shuffled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NjY48kaeK_H"
      },
      "outputs": [],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    seed = 123,\n",
        "    shuffle = True,\n",
        "    class_mode = 'categorical')\n",
        "\n",
        "\n",
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    seed = 123,\n",
        "    shuffle = False,\n",
        "    class_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_6_DXzaeK_I"
      },
      "source": [
        "This code sets the seed and ensures reproduceability for our model training. The training will work without this code, but the final model will be slighlty different each time. This code was adapted from https://stackoverflow.com/a/52897216/18022123."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJSRonOjeK_J"
      },
      "outputs": [],
      "source": [
        "# Seed value\n",
        "seed_value= 321\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(seed_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKbukPOceK_K"
      },
      "source": [
        "Here we are defining our model architecture. As a base, we are using the ImageNet ResNet50, making this a transfer learning convolutional neural network. After this we add a global average pooling layer, one dense layer with ReLu activation, and a softmax classification layer. \n",
        "\n",
        "We must also set the base layers as non-trainable so their weights are not modified.\n",
        "\n",
        "The model is then compiled and ready to be fit to the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vibtTl6peK_K"
      },
      "outputs": [],
      "source": [
        "base_model = ResNet50(include_top = False, weights = 'imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation = 'relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation = 'softmax')(x)\n",
        "model = Model(inputs = base_model.input, outputs = predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chk5Jn3BeK_L"
      },
      "source": [
        "This code trains the model using data from `train_generator` over 25 epochs. It is also tested using the test data after every epoch, which allows you to see its progression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3lkwsUkeK_L"
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator,\n",
        "          epochs = 25,\n",
        "          validation_data = test_generator)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO2R6ItXeK_M"
      },
      "source": [
        "Finally, we can create a prediction probability matrix and export it for further analysis in R."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8Hk5yXOeK_M"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(test_generator)\n",
        "preddf = pd.DataFrame(preds)\n",
        "preddf.to_csv(\"DL-Predictions.csv\", index = False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}